{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9a2c26a-d6cf-4f15-bf18-a02e4888caff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1.0)\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "     -------------------------------------- 125.7/125.7 KB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (4.5.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (23.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (2023.6.0)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (2.0.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch-lightning) (4.65.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations) (1.11.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.22.0-cp39-cp39-win_amd64.whl (24.5 MB)\n",
      "     --------------------------------------- 24.5/24.5 MB 10.6 MB/s eta 0:00:00\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.8.1.78-cp37-abi3-win_amd64.whl (38.0 MB)\n",
      "     --------------------------------------- 38.0/38.0 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.3.0)\n",
      "Collecting lazy_loader>=0.3\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2023.9.26-py3-none-any.whl (222 kB)\n",
      "     ------------------------------------- 222.9/222.9 KB 14.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (9.5.0)\n",
      "Collecting imageio>=2.27\n",
      "  Downloading imageio-2.31.5-py3-none-any.whl (313 kB)\n",
      "     -------------------------------------- 313.2/313.2 KB 9.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.12.0->pytorch-lightning) (3.12.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mrwer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n",
      "Installing collected packages: tifffile, opencv-python-headless, lazy_loader, imageio, scikit-image, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.1 imageio-2.31.5 lazy_loader-0.3 opencv-python-headless-4.8.1.78 qudida-0.0.4 scikit-image-0.22.0 tifffile-2023.9.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mrwer\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xmltodict pytorch-lightning albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb77c075-59f6-4797-a5ec-4b1e3805c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import tqdm\n",
    "import xmltodict\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33630bc3-2a36-4da0-b87a-4306a1f102da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2tag = {\"helmet\": 0}\n",
    "\n",
    "class HelmDataset(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_list = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = os.path.join(self.data_dir, self.image_list[idx])\n",
    "        xml_name = os.path.splitext(img_name)[0] + '.xml'\n",
    "\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        im_w, im_h = image.size\n",
    "        image = np.array(image)\n",
    "        boxes, class_labels = self.__get_boxes_from_xml(xml_name)\n",
    "        \n",
    "        boxes = self.__convert_to_yolo_box_params(boxes, im_w, im_h)\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image, bboxes=boxes, class_labels=class_labels)\n",
    "            image = transformed[\"image\"]\n",
    "            boxes = transformed[\"bboxes\"]\n",
    "            class_labels = transformed[\"class_labels\"]\n",
    "            \n",
    "        image = torch.tensor(image,dtype=torch.float32)\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        class_labels = torch.tensor(class_labels, dtype=torch.int)\n",
    "        \n",
    "        target_tensor = (boxes, class_labels)\n",
    "        return  image, target_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.image_list)\n",
    "        \n",
    "    def __get_boxes_from_xml(self, xml_filename: str):\n",
    "        boxes = []\n",
    "        class_labels = []\n",
    "        with open(xml_filename) as fd:\n",
    "            doc = xmltodict.parse(fd.read())\n",
    "            objects = doc['annotation']['object']\n",
    "            if not isinstance(objects, list):\n",
    "                objects = [objects]\n",
    "            \n",
    "            for object in objects:\n",
    "                box_coordinates = object['bndbox']\n",
    "                coords = [box_coordinates['xmin'], box_coordinates['ymin'], box_coordinates['xmax'], box_coordinates['ymax']]\n",
    "                boxes.append([int(x) for x in coords ])\n",
    "                class_labels.append(class2tag[object['name']])\n",
    "                  \n",
    "        return boxes, class_labels\n",
    "\n",
    "    def __convert_to_yolo_box_params(self, box_coordinates: List[int],im_w,im_h):\n",
    "        new_box_coordinates = []\n",
    "        for box in box_coordinates:\n",
    "            x_center = (box[0] + box[2]) / 2 / im_w\n",
    "            y_center = (box[1] + box[3]) / 2 / im_h\n",
    "            width = (box[2] - box[0]) / im_w\n",
    "            height = (box[3] - box[1]) / im_h\n",
    "            new_box_coordinates.append([x_center, y_center, width, height])\n",
    "    \n",
    "        return new_box_coordinates\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce5b5ddd-af75-43f4-b552-2b5990c0e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]),\n",
    ")\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ac3e245-d69e-4807-907e-e66993970593",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HelmDataset(data_dir=\"./data/train\",transforms=train_transform)\n",
    "val_dataset = HelmDataset(data_dir=\"./data/test\", transforms=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7fed2205-8f08-49a6-a7c8-8064cfab6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d42e754f-46ea-43e6-909c-0005c79b23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(predicted_bbox, gt_bbox) -> float:\n",
    "    \"\"\"\n",
    "    :param: predicted_bbox - [x_min, y_min, x_max, y_max]\n",
    "    :param: gt_bbox - [x_min, y_min, x_max, y_max]\n",
    "    \n",
    "    \"\"\"\n",
    "    intersection_bbox = np.array(\n",
    "        [\n",
    "            max(predicted_bbox[0], gt_bbox[0]),\n",
    "            max(predicted_bbox[1], gt_bbox[1]),\n",
    "            min(predicted_bbox[2], gt_bbox[2]),\n",
    "            min(predicted_bbox[3], gt_bbox[3]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    intersection_area = max(intersection_bbox[2] - intersection_bbox[0], 0) * max(intersection_bbox[3] - intersection_bbox[1], 0)\n",
    "    area_dt = (predicted_bbox[2] - predicted_bbox[0]) * (predicted_bbox[3] - predicted_bbox[1])\n",
    "    area_gt = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])\n",
    "    \n",
    "    union_area = area_dt + area_gt - intersection_area\n",
    "\n",
    "    iou = intersection_area / union_area\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb2abb-8a75-46dd-8ba7-edb4e4ba6b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
